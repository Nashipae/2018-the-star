Facebook has quickly removed a new button that asks users if every post on their feed is 'hate speech'. The company inadvertently set the feature live for 20 minutes yesterday during the company's annual F8 developer conference when conducting an 'internal test'. The button - which appears to only have been seen by US users - asked 'Does this contain hate speech?' regardless of the content If users clicked 'yes' to respond to the post they were given four options for feedback. These were 'hate speech', 'test p1', 'test p2' and 'test p3'. If users clicked 'no', the message - which appeared twice on adverts - disappeared. Users say that the message, which a company representative said was a 'bug', had been removed from every post by noon ET (17:00 BST). The feature did not give an explanation of what 'hate speech' might be and some users interpreted it differently. "So glad Facebook has finally given me the ability to report every single pro- New York Mets post as 'hate speech'," joked Andrew Mullins, who works for the Republican Governors Association on his Twitter. American writer Matt Walsh suggested that the bug might be more sinister and said it was an intentional move by Facebook to remove 'conservative content'. "If it's that easy to report a post for "hate speech," there will be no more conservative posts soon enough," he wrote on his Twitter. "Some people saw "does this post contain hate speech" today on some posts," Facebook Vice President Guy Rosen explained on Twitter. "This was a test - and a bug that we reverted within 20 mins," he said. 'It was shown for a short time on posts regardless of their content (like this one)', he explained, with a post from Mark Zuckerberg about the annual F8 developer's conference. Other users took to Twitter to complain that Facebook was a 'terrible' website. "When you click the "yes" button on the "Does this post contain hate speech?" prompt on facebook you're presented with a form that clearly wasn't supposed to be pushed to live," wrote Twitter user Kay Fabe Hutchinson, who tweets with the handle @LonestarTallBoi. "What a terrible website," he said. 'This was an internal test we were working on to understand different types of speech, including speech we thought would not be hate', a Facebook spokesperson told MailOnline. "A bug caused it to launch publicly. It's been disabled," he said. Last month Facebook announced it would have AI tools to automatically flag and remove hate speech within five to ten years. The comments were made by Mark Zuckerberg when he appeared before Congress to address mounting concerns raised in the wake of the Cambridge Analytica scandal. Estimates suggest more than 87 million users may have had their data mined by the Trump affiliated consultancy firm through the 'This Is Your Digital Life' quiz. Zuckerberg says the company has already developed intelligent software tools to root out terrorist propaganda and will continue to develop them for hate speech. The company hopes to have 20,000 employees working to review security and content issues by the end of 2018, he said. Zuckerberg made the comments during testimony before a joint hearing with the Senate judiciary and commerce committees. Nearly all ISIS and al Qaeda content that is removed from Facebook is flagged before 'any human sees it', he claimed. "That’s a success in terms of rolling out AI tools that can proactively police and enforce safety across the community," Zuckerberg added. "Hate speech, I am optimistic that over a five to ten year period we'll have AI tools that can get into some of the nuances, the linguistic nuances of different types of content to be more accurate in flagging things for our systems, but today is just not there on that." Commerce committee chairman John Thune asked the billionaire about the difficulties facing his firm in distinguishing between legitimate debate and hate speech. The Menlo Park company's boss said that creating technology to tackle hate speech is more of a challenge than other forms of problematic content. "Some problems lend themselves more easily to AI solutions than others," Zuckerberg said. "Hate speech is one of the hardest, because determining if something is hate speech is very linguistically nuanced. "You need to understand what is a slur and whether something is hateful, not just in English, but a majority of people on Facebook use it in languages that are different across the world."